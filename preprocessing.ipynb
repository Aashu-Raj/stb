{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc37d16",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PREPROCESSING NOTEBOOK\n",
    "======================\n",
    "This notebook handles:\n",
    "1. Data loading and exploration\n",
    "2. Feature engineering\n",
    "3. Data cleaning\n",
    "4. Geospatial analysis\n",
    "5. Image validation\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import Config\n",
    "from data_fetcher import SatelliteImageFetcher\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Print configuration\n",
    "Config.print_config()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 2: LOAD DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load train and test data\n",
    "train_df = pd.read_excel(Config.TRAIN_DATA_PATH)\n",
    "test_df = pd.read_excel(Config.TEST_DATA_PATH)\n",
    "\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "print(\"\\nTrain columns:\")\n",
    "print(train_df.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(train_df.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(train_df.dtypes)\n",
    "\n",
    "print(\"\\nBasic statistics:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3: EXPLORATORY DATA ANALYSIS - MISSING VALUES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "missing_train = train_df.isnull().sum()\n",
    "missing_train_pct = 100 * missing_train / len(train_df)\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing_Count': missing_train,\n",
    "    'Percentage': missing_train_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(\"\\nMissing values in training data:\")\n",
    "print(missing_df)\n",
    "\n",
    "# Visualize missing data\n",
    "if len(missing_df) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    missing_df['Percentage'].plot(kind='barh', ax=ax)\n",
    "    ax.set_xlabel('Percentage Missing (%)')\n",
    "    ax.set_title('Missing Values by Feature')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 4: TARGET VARIABLE ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TARGET VARIABLE ANALYSIS (PRICE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nPrice statistics:\")\n",
    "print(train_df['price'].describe())\n",
    "\n",
    "# Visualize price distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Histogram\n",
    "axes[0].hist(train_df['price'], bins=50, edgecolor='black')\n",
    "axes[0].set_xlabel('Price')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Price Distribution')\n",
    "\n",
    "# Log-transformed histogram\n",
    "axes[1].hist(np.log1p(train_df['price']), bins=50, edgecolor='black', color='orange')\n",
    "axes[1].set_xlabel('Log(Price)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Log-Transformed Price Distribution')\n",
    "\n",
    "# Box plot\n",
    "axes[2].boxplot(train_df['price'])\n",
    "axes[2].set_ylabel('Price')\n",
    "axes[2].set_title('Price Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check for outliers\n",
    "Q1 = train_df['price'].quantile(0.25)\n",
    "Q3 = train_df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = train_df[(train_df['price'] < Q1 - 1.5*IQR) | (train_df['price'] > Q3 + 1.5*IQR)]\n",
    "print(f\"\\nNumber of price outliers (IQR method): {len(outliers)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 5: FEATURE CORRELATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE CORRELATIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_cols = train_df.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = train_df[numeric_cols].corr()\n",
    "\n",
    "# Correlations with price\n",
    "price_correlations = correlation_matrix['price'].sort_values(ascending=False)\n",
    "print(\"\\nTop 10 features correlated with price:\")\n",
    "print(price_correlations.head(10))\n",
    "\n",
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(14, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize top correlations with price\n",
    "top_features = price_correlations.head(11).index[1:]  # Exclude price itself\n",
    "fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    axes[idx].scatter(train_df[feature], train_df['price'], alpha=0.5)\n",
    "    axes[idx].set_xlabel(feature)\n",
    "    axes[idx].set_ylabel('Price')\n",
    "    axes[idx].set_title(f'{feature} vs Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 6: GEOSPATIAL ANALYSIS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GEOSPATIAL ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check coordinate ranges\n",
    "print(f\"\\nLatitude range: {train_df['lat'].min():.4f} to {train_df['lat'].max():.4f}\")\n",
    "print(f\"Longitude range: {train_df['long'].min():.4f} to {train_df['long'].max():.4f}\")\n",
    "\n",
    "# Scatter plot: Geographic distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Simple scatter\n",
    "axes[0].scatter(train_df['long'], train_df['lat'], alpha=0.3, s=1)\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "axes[0].set_title('Property Locations')\n",
    "\n",
    "# Price heatmap\n",
    "scatter = axes[1].scatter(\n",
    "    train_df['long'], \n",
    "    train_df['lat'], \n",
    "    c=train_df['price'], \n",
    "    cmap='YlOrRd', \n",
    "    alpha=0.5,\n",
    "    s=10\n",
    ")\n",
    "axes[1].set_xlabel('Longitude')\n",
    "axes[1].set_ylabel('Latitude')\n",
    "axes[1].set_title('Property Prices by Location')\n",
    "plt.colorbar(scatter, ax=axes[1], label='Price')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Price by location statistics\n",
    "print(\"\\nPrice statistics by geographic regions:\")\n",
    "lat_bins = pd.qcut(train_df['lat'], q=4, labels=['South', 'Mid-South', 'Mid-North', 'North'])\n",
    "print(train_df.groupby(lat_bins)['price'].describe())\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 7: FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def engineer_features(df):\n",
    "    \"\"\"Create new features from existing ones\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Age of property\n",
    "    current_year = 2024\n",
    "    df['age'] = current_year - df['yr_built']\n",
    "    df['years_since_renovation'] = current_year - df['yr_renovated']\n",
    "    df['is_renovated'] = (df['yr_renovated'] > 0).astype(int)\n",
    "    \n",
    "    # Size ratios\n",
    "    df['living_lot_ratio'] = df['sqft_living'] / (df['sqft_lot'] + 1)\n",
    "    df['above_ground_ratio'] = df['sqft_above'] / (df['sqft_living'] + 1)\n",
    "    df['basement_ratio'] = df['sqft_basement'] / (df['sqft_living'] + 1)\n",
    "    \n",
    "    # Room ratios\n",
    "    df['bath_bed_ratio'] = df['bathrooms'] / (df['bedrooms'] + 1)\n",
    "    df['rooms_per_sqft'] = (df['bedrooms'] + df['bathrooms']) / (df['sqft_living'] + 1)\n",
    "    \n",
    "    # Neighborhood comparison\n",
    "    df['living_vs_neighbors'] = df['sqft_living'] / (df['sqft_living15'] + 1)\n",
    "    df['lot_vs_neighbors'] = df['sqft_lot'] / (df['sqft_lot15'] + 1)\n",
    "    \n",
    "    # Price per sqft (for train only)\n",
    "    if 'price' in df.columns:\n",
    "        df['price_per_sqft'] = df['price'] / (df['sqft_living'] + 1)\n",
    "    \n",
    "    # Quality scores\n",
    "    df['overall_quality'] = df['grade'] * df['condition']\n",
    "    df['luxury_score'] = df['grade'] + df['view'] + df['waterfront']*2\n",
    "    \n",
    "    # Log transformations for skewed features\n",
    "    for col in ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']:\n",
    "        if col in df.columns:\n",
    "            df[f'log_{col}'] = np.log1p(df[col])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply feature engineering\n",
    "train_engineered = engineer_features(train_df)\n",
    "test_engineered = engineer_features(test_df)\n",
    "\n",
    "print(f\"\\nOriginal features: {train_df.shape[1]}\")\n",
    "print(f\"After engineering: {train_engineered.shape[1]}\")\n",
    "print(f\"\\nNew features added: {train_engineered.shape[1] - train_df.shape[1]}\")\n",
    "\n",
    "new_features = [col for col in train_engineered.columns if col not in train_df.columns]\n",
    "print(f\"\\nNew feature names:\")\n",
    "for feat in new_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 8: DOWNLOAD SATELLITE IMAGES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DOWNLOADING SATELLITE IMAGES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Initialize fetcher\n",
    "fetcher = SatelliteImageFetcher()\n",
    "\n",
    "# Download images for train set\n",
    "print(\"\\nDownloading training images...\")\n",
    "train_with_images = fetcher.fetch_and_save_images(\n",
    "    train_engineered,\n",
    "    save_dir=Config.IMAGE_SAVE_DIR / 'train',\n",
    "    delay=0.1\n",
    ")\n",
    "\n",
    "# Download images for test set\n",
    "print(\"\\nDownloading test images...\")\n",
    "test_with_images = fetcher.fetch_and_save_images(\n",
    "    test_engineered,\n",
    "    save_dir=Config.IMAGE_SAVE_DIR / 'test',\n",
    "    delay=0.1\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 9: VALIDATE IMAGES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"IMAGE VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def validate_images(df, sample_size=5):\n",
    "    \"\"\"Validate and visualize sample images\"\"\"\n",
    "    valid_images = df[df['image_path'].notna()]\n",
    "    \n",
    "    print(f\"\\nValid images: {len(valid_images)}/{len(df)}\")\n",
    "    \n",
    "    # Display sample images\n",
    "    sample = valid_images.sample(min(sample_size, len(valid_images)))\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(sample), figsize=(20, 4))\n",
    "    if len(sample) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (_, row) in enumerate(sample.iterrows()):\n",
    "        img = Image.open(row['image_path'])\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        if 'price' in row:\n",
    "            axes[idx].set_title(f\"Price: ${row['price']:,.0f}\")\n",
    "        else:\n",
    "            axes[idx].set_title(f\"ID: {row['id']}\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Validate train images\n",
    "print(\"\\nSample training images:\")\n",
    "validate_images(train_with_images, sample_size=5)\n",
    "\n",
    "# Validate test images\n",
    "print(\"\\nSample test images:\")\n",
    "validate_images(test_with_images, sample_size=5)\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 10: SAVE PROCESSED DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"SAVING PROCESSED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Save processed datasets\n",
    "output_dir = Config.DATA_DIR / 'processed'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_output = output_dir / 'train_processed.csv'\n",
    "test_output = output_dir / 'test_processed.csv'\n",
    "\n",
    "train_with_images.to_csv(train_output, index=False)\n",
    "test_with_images.to_csv(test_output, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved processed training data to {train_output}\")\n",
    "print(f\"✓ Saved processed test data to {test_output}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PREPROCESSING COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Review the generated visualizations\")\n",
    "print(\"2. Check the processed data files\")\n",
    "print(\"3. Proceed to model_training.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
