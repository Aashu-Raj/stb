{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d9a9e8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MODEL TRAINING NOTEBOOK\n",
    "=======================\n",
    "This notebook trains the multimodal regression model\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 1: SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import custom modules\n",
    "from config import Config\n",
    "from model_architecture import MultimodalFusionModel, TabularOnlyModel, get_model\n",
    "from dataset import MultimodalDataset, TabularOnlyDataset, get_train_transforms, get_val_transforms\n",
    "from trainer import RealEstateTrainer, predict\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(Config.RANDOM_SEED)\n",
    "np.random.seed(Config.RANDOM_SEED)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "Config.print_config()\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 2: LOAD PROCESSED DATA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LOADING PROCESSED DATA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv(Config.DATA_DIR / 'processed' / 'train_processed.csv')\n",
    "test_df = pd.read_csv(Config.DATA_DIR / 'processed' / 'test_processed.csv')\n",
    "\n",
    "print(f\"\\nTrain shape: {train_df.shape}\")\n",
    "print(f\"Test shape: {test_df.shape}\")\n",
    "\n",
    "# Check for images\n",
    "train_with_images = train_df[train_df['image_path'].notna()]\n",
    "test_with_images = test_df[test_df['image_path'].notna()]\n",
    "\n",
    "print(f\"\\nTrain samples with images: {len(train_with_images)}/{len(train_df)}\")\n",
    "print(f\"Test samples with images: {len(test_with_images)}/{len(test_df)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 3: DEFINE FEATURES\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Tabular features to use\n",
    "tabular_features = [\n",
    "    # Basic features\n",
    "    'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "    'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "    'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
    "    \n",
    "    # Neighborhood features\n",
    "    'sqft_living15', 'sqft_lot15',\n",
    "    \n",
    "    # Location features\n",
    "    'lat', 'long',\n",
    "    \n",
    "    # Engineered features\n",
    "    'age', 'years_since_renovation', 'is_renovated',\n",
    "    'living_lot_ratio', 'above_ground_ratio', 'basement_ratio',\n",
    "    'bath_bed_ratio', 'rooms_per_sqft',\n",
    "    'living_vs_neighbors', 'lot_vs_neighbors',\n",
    "    'overall_quality', 'luxury_score',\n",
    "    'log_sqft_living', 'log_sqft_lot', 'log_sqft_above'\n",
    "]\n",
    "\n",
    "# Filter features that exist in the data\n",
    "available_features = [f for f in tabular_features if f in train_df.columns]\n",
    "print(f\"\\nUsing {len(available_features)} tabular features:\")\n",
    "for feat in available_features:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "target = 'price'\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 4: DATA PREPROCESSING AND SCALING\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA PREPROCESSING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Handle missing values\n",
    "for col in available_features:\n",
    "    if train_df[col].isnull().any():\n",
    "        median_val = train_df[col].median()\n",
    "        train_df[col].fillna(median_val, inplace=True)\n",
    "        test_df[col].fillna(median_val, inplace=True)\n",
    "        print(f\"Filled {col} missing values with median: {median_val}\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "train_df[available_features] = scaler.fit_transform(train_df[available_features])\n",
    "test_df[available_features] = scaler.transform(test_df[available_features])\n",
    "\n",
    "print(\"\\n‚úì Features scaled using StandardScaler\")\n",
    "\n",
    "# Split train into train and validation\n",
    "train_data, val_data = train_test_split(\n",
    "    train_df,\n",
    "    test_size=Config.TEST_SIZE,\n",
    "    random_state=Config.RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain samples: {len(train_data)}\")\n",
    "print(f\"Validation samples: {len(val_data)}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 5: CREATE DATASETS AND DATALOADERS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CREATING DATASETS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create multimodal datasets\n",
    "train_dataset = MultimodalDataset(\n",
    "    df=train_data,\n",
    "    tabular_features=available_features,\n",
    "    target_column=target,\n",
    "    transform=get_train_transforms(),\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "val_dataset = MultimodalDataset(\n",
    "    df=val_data,\n",
    "    tabular_features=available_features,\n",
    "    target_column=target,\n",
    "    transform=get_val_transforms(),\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "test_dataset = MultimodalDataset(\n",
    "    df=test_df,\n",
    "    tabular_features=available_features,\n",
    "    transform=get_val_transforms(),\n",
    "    is_test=True\n",
    ")\n",
    "\n",
    "print(f\"\\nMultimodal datasets created:\")\n",
    "print(f\"  Train: {len(train_dataset)} samples\")\n",
    "print(f\"  Validation: {len(val_dataset)} samples\")\n",
    "print(f\"  Test: {len(test_dataset)} samples\")\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì DataLoaders created\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 6: CREATE BASELINE MODEL (TABULAR ONLY)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING BASELINE MODEL (TABULAR ONLY)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Create tabular-only datasets\n",
    "train_tab_dataset = TabularOnlyDataset(\n",
    "    df=train_data,\n",
    "    tabular_features=available_features,\n",
    "    target_column=target,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "val_tab_dataset = TabularOnlyDataset(\n",
    "    df=val_data,\n",
    "    tabular_features=available_features,\n",
    "    target_column=target,\n",
    "    is_test=False\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "train_tab_loader = DataLoader(\n",
    "    train_tab_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "val_tab_loader = DataLoader(\n",
    "    val_tab_dataset,\n",
    "    batch_size=Config.BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4\n",
    ")\n",
    "\n",
    "# Initialize baseline model\n",
    "baseline_model = TabularOnlyModel(\n",
    "    input_dim=len(available_features),\n",
    "    hidden_dims=[256, 128, 64],\n",
    "    dropout=0.3\n",
    ")\n",
    "\n",
    "# Setup training\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(baseline_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "baseline_trainer = RealEstateTrainer(\n",
    "    model=baseline_model,\n",
    "    train_loader=train_tab_loader,\n",
    "    val_loader=val_tab_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    device=device,\n",
    "    model_name='baseline_tabular',\n",
    "    save_dir=Config.MODEL_SAVE_DIR\n",
    ")\n",
    "\n",
    "# Train\n",
    "baseline_history = baseline_trainer.train(\n",
    "    epochs=Config.EPOCHS,\n",
    "    scheduler=scheduler,\n",
    "    early_stopping_patience=10\n",
    ")\n",
    "\n",
    "# Plot history\n",
    "baseline_trainer.plot_history(\n",
    "    save_path=Config.MODEL_SAVE_DIR / 'baseline_training_history.png'\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 7: CREATE MULTIMODAL MODEL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING MULTIMODAL MODEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test different fusion strategies\n",
    "fusion_strategies = ['late', 'early', 'attention']\n",
    "multimodal_results = {}\n",
    "\n",
    "for strategy in fusion_strategies:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Training with {strategy.upper()} fusion strategy\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Initialize model\n",
    "    multimodal_model = MultimodalFusionModel(\n",
    "        tabular_input_dim=len(available_features),\n",
    "        image_embedding_dim=512,\n",
    "        tabular_hidden_dims=[256, 128, 64],\n",
    "        fusion_strategy=strategy,\n",
    "        dropout=0.3\n",
    "    )\n",
    "    \n",
    "    # Setup training\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(multimodal_model.parameters(), lr=Config.LEARNING_RATE)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=5, verbose=True\n",
    "    )\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = RealEstateTrainer(\n",
    "        model=multimodal_model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        criterion=criterion,\n",
    "        device=device,\n",
    "        model_name=f'multimodal_{strategy}',\n",
    "        save_dir=Config.MODEL_SAVE_DIR\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    history = trainer.train(\n",
    "        epochs=Config.EPOCHS,\n",
    "        scheduler=scheduler,\n",
    "        early_stopping_patience=10\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    multimodal_results[strategy] = {\n",
    "        'history': history,\n",
    "        'best_val_loss': trainer.best_val_loss\n",
    "    }\n",
    "    \n",
    "    # Plot history\n",
    "    trainer.plot_history(\n",
    "        save_path=Config.MODEL_SAVE_DIR / f'multimodal_{strategy}_training_history.png'\n",
    "    )\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 8: COMPARE MODELS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Prepare comparison data\n",
    "comparison_data = {\n",
    "    'Model': ['Tabular Only'],\n",
    "    'Best Val Loss': [baseline_trainer.best_val_loss],\n",
    "    'Final Val MAE': [baseline_history['val_mae'][-1]],\n",
    "    'Final Val RMSE': [baseline_history['val_rmse'][-1]],\n",
    "    'Final Val MAPE': [baseline_history['val_mape'][-1]]\n",
    "}\n",
    "\n",
    "for strategy, results in multimodal_results.items():\n",
    "    comparison_data['Model'].append(f'Multimodal ({strategy})')\n",
    "    comparison_data['Best Val Loss'].append(results['best_val_loss'])\n",
    "    comparison_data['Final Val MAE'].append(results['history']['val_mae'][-1])\n",
    "    comparison_data['Final Val RMSE'].append(results['history']['val_rmse'][-1])\n",
    "    comparison_data['Final Val MAPE'].append(results['history']['val_mape'][-1])\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"\\n\", comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "metrics = ['Best Val Loss', 'Final Val MAE', 'Final Val RMSE', 'Final Val MAPE']\n",
    "for idx, metric in enumerate(metrics):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    ax.bar(comparison_df['Model'], comparison_df[metric])\n",
    "    ax.set_title(metric)\n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(Config.MODEL_SAVE_DIR / 'model_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find best model\n",
    "best_model_idx = comparison_df['Best Val Loss'].idxmin()\n",
    "best_model_name = comparison_df.loc[best_model_idx, 'Model']\n",
    "print(f\"\\nüèÜ Best Model: {best_model_name}\")\n",
    "print(f\"   Best Val Loss: {comparison_df.loc[best_model_idx, 'Best Val Loss']:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CELL 9: GENERATE PREDICTIONS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING TEST PREDICTIONS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best multimodal model (assuming 'late' fusion is best)\n",
    "best_strategy = 'late'\n",
    "best_model = MultimodalFusionModel(\n",
    "    tabular_input_dim=len(available_features),\n",
    "    image_embedding_dim=512,\n",
    "    tabular_hidden_dims=[256, 128, 64],\n",
    "    fusion_strategy=best_strategy,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint_path = Config.MODEL_SAVE_DIR / f'multimodal_{best_strategy}_best.pth'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "best_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"‚úì Loaded best model from {checkpoint_path}\")\n",
    "\n",
    "# Make predictions\n",
    "predictions, ids = predict(best_model, test_loader, device=device)\n",
    "\n",
    "# Create submission file\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'predicted_price': predictions\n",
    "})\n",
    "\n",
    "submission_df = submission_df.sort_values('id')\n",
    "submission_path = 'predictions.csv'\n",
    "submission_df.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úì Predictions saved to {submission_path}\")\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(submission_df['predicted_price'].describe())\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(submission_df['predicted_price'], bins=50, edgecolor='black')\n",
    "plt.xlabel('Predicted Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Predicted Prices')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(np.log1p(submission_df['predicted_price']), bins=50, edgecolor='black', color='orange')\n",
    "plt.xlabel('Log(Predicted Price)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Log Distribution of Predicted Prices')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('prediction_distribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING AND PREDICTION COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nFiles generated:\")\n",
    "print(f\"  - predictions.csv\")\n",
    "print(f\"  - Model checkpoints in {Config.MODEL_SAVE_DIR}\")\n",
    "print(f\"  - Training history plots\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
